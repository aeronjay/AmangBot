{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6lwubWthKRS4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Dataset loaded: 171,284 characters\n",
            "üìÑ Estimated pages: ~85\n"
          ]
        }
      ],
      "source": [
        "with open('Dataset/StudentHandbookDataset.txt', 'r', encoding='utf-8') as f:\n",
        "    dataset = f.read()\n",
        "\n",
        "print(f\"üìö Dataset loaded: {len(dataset):,} characters\")\n",
        "print(f\"üìÑ Estimated pages: ~{len(dataset) // 2000}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PO-VTc7SLhaB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M02nSUMzMnlT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîß Initializing embedding model...\n",
            "‚úÖ Embedding model loaded: all-mpnet-base-v2 (768 dimensions)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüîß Initializing embedding model...\")\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\",  # Best quality for academic text\n",
        "    model_kwargs={\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'trust_remote_code': True\n",
        "    },\n",
        "    encode_kwargs={'normalize_embeddings': True}\n",
        ")\n",
        "print(\"‚úÖ Embedding model loaded: all-mpnet-base-v2 (768 dimensions)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "mHOQc4rbMqXh",
        "outputId": "747d16c1-3d93-41f8-f8fc-8422801c1c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîß Setting up semantic chunker...\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüîß Setting up semantic chunker...\")\n",
        "text_splitter = SemanticChunker(\n",
        "    embeddings=embedding_model,\n",
        "    breakpoint_threshold_type=\"percentile\",\n",
        "    breakpoint_threshold_amount=80,  # Good balance for policy docs\n",
        "    buffer_size=1,\n",
        "    add_start_index=True  # Track position in original text\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qB0XgPU_MxJs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìù Creating semantic chunks from raw text...\n",
            "‚úÖ Created 246 semantic chunks\n",
            "\n",
            "üìä Chunk Analysis:\n",
            "   Average size: 650 characters\n",
            "   Size range: 2 - 10109 characters\n",
            "   Total chunks: 246\n",
            "\n",
            "üìã Sample chunks:\n",
            "   Chunk 1: ÔªøRepublic of the Philippines  Eulogio \"Amang\" Rodriguez Institute of Science and Technology Office of Student Affairs and Services   EARIST STUDENT HA...\n",
            "   Chunk 2: ii - HISTORY OF EARIST ..... 1 - MISSION STATEMENTS   - Vision ..... 3   - Mission ..... 3   - Goal ........\n",
            "   Chunk 3: 3   - Objectives ..... 3 - CURRICULAR OFFERINGS   - Main Campus     - College of Architecture and Fine Arts ..... 4     - College of Arts and Sciences...\n"
          ]
        }
      ],
      "source": [
        "# 3. Split raw text into semantic chunks using create_documents\n",
        "print(\"\\nüìù Creating semantic chunks from raw text...\")\n",
        "chunks = text_splitter.create_documents([dataset])\n",
        "print(f\"‚úÖ Created {len(chunks)} semantic chunks\")\n",
        "\n",
        "# Analyze chunk quality\n",
        "chunk_sizes = [len(chunk.page_content) for chunk in chunks]\n",
        "print(f\"\\nüìä Chunk Analysis:\")\n",
        "print(f\"   Average size: {np.mean(chunk_sizes):.0f} characters\")\n",
        "print(f\"   Size range: {min(chunk_sizes)} - {max(chunk_sizes)} characters\")\n",
        "print(f\"   Total chunks: {len(chunks)}\")\n",
        "\n",
        "# Show sample chunks\n",
        "print(\"\\nüìã Sample chunks:\")\n",
        "for i in range(min(3, len(chunks))):\n",
        "    chunk_preview = chunks[i].page_content[:150].replace('\\n', ' ')\n",
        "    print(f\"   Chunk {i+1}: {chunk_preview}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nFQFs9KNNAaV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîÑ Generating embeddings for all chunks...\n",
            "   Processed batch 1/8\n",
            "   Processed batch 2/8\n",
            "   Processed batch 3/8\n",
            "   Processed batch 4/8\n",
            "   Processed batch 5/8\n",
            "   Processed batch 6/8\n",
            "   Processed batch 7/8\n",
            "   Processed batch 8/8\n",
            "‚úÖ Generated 246 embeddings\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüîÑ Generating embeddings for all chunks...\")\n",
        "chunk_texts = [chunk.page_content for chunk in chunks]\n",
        "\n",
        "# Process embeddings in batches to avoid memory issues\n",
        "batch_size = 32\n",
        "all_embeddings = []\n",
        "for i in range(0, len(chunk_texts), batch_size):\n",
        "    batch = chunk_texts[i:i+batch_size]\n",
        "    batch_embeddings = embedding_model.embed_documents(batch)\n",
        "    all_embeddings.extend(batch_embeddings)\n",
        "    print(f\"   Processed batch {i//batch_size + 1}/{(len(chunk_texts) + batch_size - 1)//batch_size}\")\n",
        "\n",
        "print(f\"‚úÖ Generated {len(all_embeddings)} embeddings\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5i17OmITR15R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üóÑÔ∏è Building FAISS vector database...\n",
            "‚úÖ FAISS index ready: 246 vectors (768 dimensions)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 5. Build FAISS vector store for fast similarity search\n",
        "print(\"\\nüóÑÔ∏è Building FAISS vector database...\")\n",
        "dimension = len(all_embeddings[0])\n",
        "index = faiss.IndexFlatIP(dimension)  # Inner Product for cosine similarity\n",
        "\n",
        "# Normalize embeddings for proper cosine similarity\n",
        "embeddings_array = np.array(all_embeddings).astype('float32')\n",
        "faiss.normalize_L2(embeddings_array)\n",
        "index.add(embeddings_array)\n",
        "\n",
        "print(f\"‚úÖ FAISS index ready: {index.ntotal:,} vectors ({dimension} dimensions)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8gWt_mVDR6JG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ü§ñ Loading language model...\n"
          ]
        }
      ],
      "source": [
        "# 6. Load high-quality language model for generation\n",
        "print(\"\\nü§ñ Loading language model...\")\n",
        "\n",
        "# Configure 4-bit quantization for T4 GPU\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605,
          "referenced_widgets": [
            "f6083f262ff74f9c8dd3820ed787a4db",
            "2191a707ba3a437eabc744405a64f93b",
            "8195b7fbb54f4fc9986ba5dd1232466a",
            "16815630fc674445b7df365ba985e757",
            "322baa0ca70d4c998e1d894c8bf1b66f",
            "93acf4c120144364a9e43a3937097baa",
            "172c56acb79f497f8985590257be24ad",
            "a9552bbda5644379a4d3404cdd78203a",
            "71ef304dfd004056979996bd1079b5b7",
            "f3eff883b8044c91abed9e5cfabd1d39",
            "b3c002ec65d14394909d6202e8700300",
            "f440cd55da25456c95d0a3112bcd682f",
            "649f0979ee2a40188bbb85a465dfc06a",
            "d46b43d325e34ae290de7270807640be",
            "7fe5b407fdf04726bee8399dd0db740c",
            "7e5bd2b3c937467ab011f471d19a7113",
            "a77e316a928c48beb4ced6822ffafe7e"
          ]
        },
        "id": "YiFKAGXETJCC",
        "outputId": "59b21685-ec41-4c22-d0be-af2ac5ed5c01"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1fec17a8cc3466ebf60f0078a4aebc5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# This will prompt you to enter your HF token\n",
        "notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "A8hW1JHAST30",
        "outputId": "79f6b1f7-0c93-41da-9275-13df556c453a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95829d6012c04fd8b5c331f2110219fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model loaded: mistralai/Mistral-7B-Instruct-v0.1\n",
            "üéØ GPU Memory: 8.5GB\n"
          ]
        }
      ],
      "source": [
        "# Use Mistral 7B for quality (perfect for T4)\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Model loaded: {model_name}\")\n",
        "print(f\"üéØ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZiwRK31dZ-v5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "üöÄ RAG System Ready!\n",
            "Testing with university-specific questions...\n",
            "\n",
            "‚ùì Question: What are the graduation requirements?\n",
            "======================================================================\n",
            "üìö Found relevant handbook sections:\n",
            "\n",
            "üìÑ Section 1 (Relevance: 0.676)\n",
            "   GRADUATION REQUIREMENTS   ### 9.1 A candidate for graduation shall file an application for graduation to the Registrar's Office. ### 9.2 A student shall be recommended for graduation when he/she has s...\n",
            "\n",
            "üìÑ Section 2 (Relevance: 0.610)\n",
            "   2. Must carry a minimum academic load of 18 units (except for graduating students). 3....\n",
            "\n",
            "üìÑ Section 3 (Relevance: 0.586)\n",
            "   Must have a passing grade in all subjects including P.E. and NSTP (MTSLTS/CWTS) enrolled in order to qualify for continuance for the following semester. ##### b....\n",
            "\n",
            "üìÑ Section 4 (Relevance: 0.574)\n",
            "   TERTIARY EDUCATION PROGRAM   ##### a. Qualifications 1....\n",
            "\n",
            "üìÑ Section 5 (Relevance: 0.553)\n",
            "   ### 10.2.2 Every candidate for graduation with honors must:   #### 10.2.4.1 Have carried the normal load prescribed in his/her curriculum (Art. II Sec.1); have completed the program within the prescri...\n",
            "\n",
            "ü§î Generating answer...\n",
            "\n",
            "üí° Answer:\n",
            "Based on the provided handbook sections, the graduation requirements for the Institute are as follows:\n",
            "\n",
            "1. A candidate for graduation must file an application for graduation to the Registrar's Office.\n",
            "2. A student must satisfy all academic and other requirements prescribed by the Institute in order to be recommended for graduation.\n",
            "3. Transfer students must earn more than 50% of the academic units required in their curriculum in order to graduate from the Institute.\n",
            "4. Deficiencies in a candidate's record must be made up and cleared before the end of their last semester or the date specified in the academic calendar in order to graduate.\n",
            "5. No diploma or transcript of records will be issued to a student until they have been cleared of all accountabilities.\n",
            "6. A student must carry a minimum academic load of 18 units (except for graduating students).\n",
            "7. A student must have a passing grade in all subjects, including P.E. and NSTP (MTSLTS/CWTS), in order to qualify for continuance for the following semester.\n",
            "8. To qualify for graduation with honors, a candidate must carry the normal load prescribed in their curriculum, complete the program within the prescribed number of years, complete at least 75% of the total number of academic units required for graduation, be in residence for at least three years immediately prior to graduation, have no final grade lower than 2.25 in the curriculum in any academic and non-academic courses, have no incomplete, dropped, and final grades of 5.0 in any academic and non-ac\n",
            "\n",
            "======================================================================\n",
            "\n",
            "üìã System Summary:\n",
            "   üìö Processed: 246 semantic chunks\n",
            "   üîç Embeddings: 246 vectors\n",
            "   ü§ñ Model: mistralai/Mistral-7B-Instruct-v0.1\n",
            "   üíæ Ready for queries!\n"
          ]
        }
      ],
      "source": [
        "def retrieve_relevant_chunks(query, top_k=5):\n",
        "    \"\"\"Find most relevant chunks for the query\"\"\"\n",
        "    # Embed the query\n",
        "    query_embedding = embedding_model.embed_query(query)\n",
        "    query_vector = np.array([query_embedding]).astype('float32')\n",
        "    faiss.normalize_L2(query_vector)\n",
        "\n",
        "    # Search FAISS index\n",
        "    scores, indices = index.search(query_vector, top_k)\n",
        "\n",
        "    # Return results with metadata\n",
        "    results = []\n",
        "    for idx, score in zip(indices[0], scores[0]):\n",
        "        if idx < len(chunks):  # Safety check\n",
        "            chunk = chunks[idx]\n",
        "            results.append({\n",
        "                'text': chunk.page_content,\n",
        "                'score': float(score),\n",
        "                'chunk_id': int(idx),\n",
        "                'start_pos': chunk.metadata.get('start_index', 0) if hasattr(chunk, 'metadata') else 0\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "def generate_answer(query, context_chunks, max_new_tokens=350):\n",
        "    \"\"\"Generate answer using retrieved context\"\"\"\n",
        "    # Combine context from relevant chunks\n",
        "    context_parts = []\n",
        "    for i, chunk in enumerate(context_chunks):\n",
        "        context_parts.append(f\"[Section {i+1}]\\n{chunk['text']}\")\n",
        "\n",
        "    combined_context = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "    # Create optimized prompt for university handbook\n",
        "    prompt = f\"\"\"<s>[INST] You are a university student advisor with access to the official student handbook. Answer the student's question accurately using only the provided handbook sections.\n",
        "\n",
        "HANDBOOK SECTIONS:\n",
        "{combined_context}\n",
        "\n",
        "STUDENT QUESTION: {query}\n",
        "\n",
        "Provide a clear, helpful answer based on the handbook information above. If the handbook doesn't contain enough information, say so. Be specific about policies, procedures, and requirements. [/INST]\"\"\"\n",
        "\n",
        "    # Tokenize and generate\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=3072)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=0.2,  # Low for factual accuracy\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Extract generated answer\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    answer_start = response.find(\"[/INST]\") + len(\"[/INST]\")\n",
        "    answer = response[answer_start:].strip()\n",
        "\n",
        "    return answer\n",
        "\n",
        "def ask_handbook(question, top_k=5, show_sources=True):\n",
        "    \"\"\"Complete RAG pipeline for handbook queries\"\"\"\n",
        "    print(f\"\\n‚ùì Question: {question}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Retrieve relevant sections\n",
        "    relevant_chunks = retrieve_relevant_chunks(question, top_k)\n",
        "\n",
        "    if not relevant_chunks:\n",
        "        print(\"‚ùå No relevant information found in handbook\")\n",
        "        return None\n",
        "\n",
        "    if show_sources:\n",
        "        print(\"üìö Found relevant handbook sections:\")\n",
        "        for i, chunk in enumerate(relevant_chunks):\n",
        "            print(f\"\\nüìÑ Section {i+1} (Relevance: {chunk['score']:.3f})\")\n",
        "            preview = chunk['text'][:200].replace('\\n', ' ')\n",
        "            print(f\"   {preview}...\")\n",
        "\n",
        "    # Generate answer\n",
        "    print(\"\\nü§î Generating answer...\")\n",
        "    answer = generate_answer(question, relevant_chunks)\n",
        "\n",
        "    print(f\"\\nüí° Answer:\")\n",
        "    print(answer)\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "    return {\n",
        "        'question': question,\n",
        "        'answer': answer,\n",
        "        'sources': relevant_chunks,\n",
        "        'num_sources': len(relevant_chunks)\n",
        "    }\n",
        "\n",
        "# Test the system\n",
        "print(\"\\n\\nüöÄ RAG System Ready!\")\n",
        "print(\"Testing with university-specific questions...\")\n",
        "\n",
        "# Sample test questions for university handbook\n",
        "test_questions = [\n",
        "    \"What are the graduation requirements?\",\n",
        "    \"How do I withdraw from a course?\",\n",
        "    \"What is the academic probation policy?\",\n",
        "    \"What happens if I'm caught cheating?\",\n",
        "    \"How do I change my major?\"\n",
        "]\n",
        "\n",
        "# Run a test query\n",
        "test_result = ask_handbook(test_questions[0])\n",
        "\n",
        "# Interactive query function\n",
        "def interactive_mode():\n",
        "    \"\"\"Interactive mode for asking questions\"\"\"\n",
        "    print(\"\\nüéì Interactive University Handbook Assistant\")\n",
        "    print(\"Type 'quit' to exit\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\n‚ùì Your question: \").strip()\n",
        "\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"üëã Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not question:\n",
        "            print(\"Please enter a question!\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            ask_handbook(question)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {str(e)}\")\n",
        "\n",
        "# Uncomment to start interactive mode\n",
        "# interactive_mode()\n",
        "\n",
        "print(\"\\nüìã System Summary:\")\n",
        "print(f\"   üìö Processed: {len(chunks):,} semantic chunks\")\n",
        "print(f\"   üîç Embeddings: {len(all_embeddings):,} vectors\")\n",
        "print(f\"   ü§ñ Model: {model_name}\")\n",
        "print(f\"   üíæ Ready for queries!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NWU8gAYsanLa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéì Interactive University Handbook Assistant\n",
            "Type 'quit' to exit\n",
            "--------------------------------------------------\n",
            "\n",
            "‚ùì Question: What are the grounds for thesis failure?\n",
            "======================================================================\n",
            "üìö Found relevant handbook sections:\n",
            "\n",
            "üìÑ Section 1 (Relevance: 0.426)\n",
            "   Obtain a failing grade......\n",
            "\n",
            "üìÑ Section 2 (Relevance: 0.383)\n",
            "   * b. Obtain a failing grade during term... * c....\n",
            "\n",
            "üìÑ Section 3 (Relevance: 0.374)\n",
            "   * d. Failure to enroll... * e....\n",
            "\n",
            "üìÑ Section 4 (Relevance: 0.265)\n",
            "   Such proponents/sources shall be held answerable in case of complaints....\n",
            "\n",
            "üìÑ Section 5 (Relevance: 0.255)\n",
            "   Expulsion ‚Äì the act of forcing someone to leave with justifiable cause or reason. Failed Grade ‚Äì a grade given to a student who does not qualify for passing a subject....\n",
            "\n",
            "ü§î Generating answer...\n",
            "\n",
            "üí° Answer:\n",
            "Based on the provided handbook sections, it appears that there is no specific section regarding the grounds for thesis failure. However, Section 5 mentions expulsion as the act of forcing someone to leave with justifiable cause or reason. It is possible that failure to meet certain academic standards or violating university policies could lead to expulsion. Additionally, obtaining a failing grade during term (as mentioned in Section 2) could also result in academic probation or suspension, which may ultimately lead to expulsion if not resolved. It is recommended to consult with an academic advisor or the relevant department for more information on the specific requirements and policies related to thesis failure.\n",
            "\n",
            "======================================================================\n",
            "üëã Goodbye!\n"
          ]
        }
      ],
      "source": [
        "interactive_mode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-IVr9nJbuwD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16815630fc674445b7df365ba985e757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f440cd55da25456c95d0a3112bcd682f",
            "style": "IPY_MODEL_649f0979ee2a40188bbb85a465dfc06a",
            "value": true
          }
        },
        "172c56acb79f497f8985590257be24ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "2191a707ba3a437eabc744405a64f93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9552bbda5644379a4d3404cdd78203a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_71ef304dfd004056979996bd1079b5b7",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "322baa0ca70d4c998e1d894c8bf1b66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d46b43d325e34ae290de7270807640be",
            "style": "IPY_MODEL_7fe5b407fdf04726bee8399dd0db740c",
            "tooltip": ""
          }
        },
        "649f0979ee2a40188bbb85a465dfc06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71ef304dfd004056979996bd1079b5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e5bd2b3c937467ab011f471d19a7113": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe5b407fdf04726bee8399dd0db740c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8195b7fbb54f4fc9986ba5dd1232466a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f3eff883b8044c91abed9e5cfabd1d39",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b3c002ec65d14394909d6202e8700300",
            "value": ""
          }
        },
        "93acf4c120144364a9e43a3937097baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e5bd2b3c937467ab011f471d19a7113",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a77e316a928c48beb4ced6822ffafe7e",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "a77e316a928c48beb4ced6822ffafe7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9552bbda5644379a4d3404cdd78203a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c002ec65d14394909d6202e8700300": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d46b43d325e34ae290de7270807640be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3eff883b8044c91abed9e5cfabd1d39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f440cd55da25456c95d0a3112bcd682f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6083f262ff74f9c8dd3820ed787a4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2191a707ba3a437eabc744405a64f93b",
              "IPY_MODEL_8195b7fbb54f4fc9986ba5dd1232466a",
              "IPY_MODEL_16815630fc674445b7df365ba985e757",
              "IPY_MODEL_322baa0ca70d4c998e1d894c8bf1b66f",
              "IPY_MODEL_93acf4c120144364a9e43a3937097baa"
            ],
            "layout": "IPY_MODEL_172c56acb79f497f8985590257be24ad"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
