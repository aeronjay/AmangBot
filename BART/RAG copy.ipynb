{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6lwubWthKRS4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Dataset loaded: 171,284 characters\n",
      "üìÑ Estimated pages: ~85\n"
     ]
    }
   ],
   "source": [
    "with open('Dataset/StudentHandbookDataset.txt', 'r', encoding='utf-8') as f:\n",
    "    dataset = f.read()\n",
    "\n",
    "print(f\"üìö Dataset loaded: {len(dataset):,} characters\")\n",
    "print(f\"üìÑ Estimated pages: ~{len(dataset) // 2000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PO-VTc7SLhaB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M02nSUMzMnlT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Initializing embedding model...\n",
      "‚úÖ Embedding model loaded: all-mpnet-base-v2 (768 dimensions)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß Initializing embedding model...\")\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",  # Best quality for academic text\n",
    "    model_kwargs={\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'trust_remote_code': True\n",
    "    },\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "print(\"‚úÖ Embedding model loaded: all-mpnet-base-v2 (768 dimensions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "mHOQc4rbMqXh",
    "outputId": "747d16c1-3d93-41f8-f8fc-8422801c1c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Setting up semantic chunker...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß Setting up semantic chunker...\")\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=80,  # Good balance for policy docs\n",
    "    buffer_size=1,\n",
    "    add_start_index=True  # Track position in original text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qB0XgPU_MxJs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Creating semantic chunks from raw text...\n",
      "‚úÖ Created 246 semantic chunks\n",
      "\n",
      "üìä Chunk Analysis:\n",
      "   Average size: 650 characters\n",
      "   Size range: 2 - 10109 characters\n",
      "   Total chunks: 246\n",
      "\n",
      "üìã Sample chunks:\n",
      "   Chunk 1: ÔªøRepublic of the Philippines  Eulogio \"Amang\" Rodriguez Institute of Science and Technology Office of Student Affairs and Services   EARIST STUDENT HA...\n",
      "   Chunk 2: ii - HISTORY OF EARIST ..... 1 - MISSION STATEMENTS   - Vision ..... 3   - Mission ..... 3   - Goal ........\n",
      "   Chunk 3: 3   - Objectives ..... 3 - CURRICULAR OFFERINGS   - Main Campus     - College of Architecture and Fine Arts ..... 4     - College of Arts and Sciences...\n"
     ]
    }
   ],
   "source": [
    "# 3. Split raw text into semantic chunks using create_documents\n",
    "print(\"\\nüìù Creating semantic chunks from raw text...\")\n",
    "chunks = text_splitter.create_documents([dataset])\n",
    "print(f\"‚úÖ Created {len(chunks)} semantic chunks\")\n",
    "\n",
    "# Analyze chunk quality\n",
    "chunk_sizes = [len(chunk.page_content) for chunk in chunks]\n",
    "print(f\"\\nüìä Chunk Analysis:\")\n",
    "print(f\"   Average size: {np.mean(chunk_sizes):.0f} characters\")\n",
    "print(f\"   Size range: {min(chunk_sizes)} - {max(chunk_sizes)} characters\")\n",
    "print(f\"   Total chunks: {len(chunks)}\")\n",
    "\n",
    "# Show sample chunks\n",
    "print(\"\\nüìã Sample chunks:\")\n",
    "for i in range(min(3, len(chunks))):\n",
    "    chunk_preview = chunks[i].page_content[:150].replace('\\n', ' ')\n",
    "    print(f\"   Chunk {i+1}: {chunk_preview}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nFQFs9KNNAaV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Generating embeddings for all chunks...\n",
      "   Processed batch 1/8\n",
      "   Processed batch 2/8\n",
      "   Processed batch 3/8\n",
      "   Processed batch 4/8\n",
      "   Processed batch 5/8\n",
      "   Processed batch 6/8\n",
      "   Processed batch 7/8\n",
      "   Processed batch 8/8\n",
      "‚úÖ Generated 246 embeddings\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÑ Generating embeddings for all chunks...\")\n",
    "chunk_texts = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "# Process embeddings in batches to avoid memory issues\n",
    "batch_size = 32\n",
    "all_embeddings = []\n",
    "for i in range(0, len(chunk_texts), batch_size):\n",
    "    batch = chunk_texts[i:i+batch_size]\n",
    "    batch_embeddings = embedding_model.embed_documents(batch)\n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "    print(f\"   Processed batch {i//batch_size + 1}/{(len(chunk_texts) + batch_size - 1)//batch_size}\")\n",
    "\n",
    "print(f\"‚úÖ Generated {len(all_embeddings)} embeddings\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5i17OmITR15R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üóÑÔ∏è Building FAISS vector database...\n",
      "‚úÖ FAISS index ready: 246 vectors (768 dimensions)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Build FAISS vector store for fast similarity search\n",
    "print(\"\\nüóÑÔ∏è Building FAISS vector database...\")\n",
    "dimension = len(all_embeddings[0])\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product for cosine similarity\n",
    "\n",
    "# Normalize embeddings for proper cosine similarity\n",
    "embeddings_array = np.array(all_embeddings).astype('float32')\n",
    "faiss.normalize_L2(embeddings_array)\n",
    "index.add(embeddings_array)\n",
    "\n",
    "print(f\"‚úÖ FAISS index ready: {index.ntotal:,} vectors ({dimension} dimensions)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8gWt_mVDR6JG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Loading language model...\n"
     ]
    }
   ],
   "source": [
    "# 6. Load high-quality language model for generation\n",
    "print(\"\\nü§ñ Loading language model...\")\n",
    "\n",
    "# Configure 4-bit quantization for T4 GPU\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605,
     "referenced_widgets": [
      "f6083f262ff74f9c8dd3820ed787a4db",
      "2191a707ba3a437eabc744405a64f93b",
      "8195b7fbb54f4fc9986ba5dd1232466a",
      "16815630fc674445b7df365ba985e757",
      "322baa0ca70d4c998e1d894c8bf1b66f",
      "93acf4c120144364a9e43a3937097baa",
      "172c56acb79f497f8985590257be24ad",
      "a9552bbda5644379a4d3404cdd78203a",
      "71ef304dfd004056979996bd1079b5b7",
      "f3eff883b8044c91abed9e5cfabd1d39",
      "b3c002ec65d14394909d6202e8700300",
      "f440cd55da25456c95d0a3112bcd682f",
      "649f0979ee2a40188bbb85a465dfc06a",
      "d46b43d325e34ae290de7270807640be",
      "7fe5b407fdf04726bee8399dd0db740c",
      "7e5bd2b3c937467ab011f471d19a7113",
      "a77e316a928c48beb4ced6822ffafe7e"
     ]
    },
    "id": "YiFKAGXETJCC",
    "outputId": "59b21685-ec41-4c22-d0be-af2ac5ed5c01"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fec17a8cc3466ebf60f0078a4aebc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# This will prompt you to enter your HF token\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "A8hW1JHAST30",
    "outputId": "79f6b1f7-0c93-41da-9275-13df556c453a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a1a567d3bc4858af2a5fc7fda37e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded: mistralai/Mistral-7B-Instruct-v0.1\n",
      "üéØ GPU Memory: 8.5GB\n"
     ]
    }
   ],
   "source": [
    "# Use Mistral 7B for quality (perfect for T4)\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {model_name}\")\n",
    "print(f\"üéØ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZiwRK31dZ-v5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üöÄ RAG System Ready!\n",
      "Testing with university-specific questions...\n",
      "\n",
      "üìã System Summary:\n",
      "   üìö Processed: 246 semantic chunks\n",
      "   üîç Embeddings: 246 vectors\n",
      "   ü§ñ Model: mistralai/Mistral-7B-Instruct-v0.1\n",
      "   üíæ Ready for queries!\n"
     ]
    }
   ],
   "source": [
    "def retrieve_relevant_chunks(query, top_k=5):\n",
    "    \"\"\"Find most relevant chunks for the query\"\"\"\n",
    "    # Embed the query\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    query_vector = np.array([query_embedding]).astype('float32')\n",
    "    faiss.normalize_L2(query_vector)\n",
    "\n",
    "    # Search FAISS index\n",
    "    scores, indices = index.search(query_vector, top_k)\n",
    "\n",
    "    # Return results with metadata\n",
    "    results = []\n",
    "    for idx, score in zip(indices[0], scores[0]):\n",
    "        if idx < len(chunks):  # Safety check\n",
    "            chunk = chunks[idx]\n",
    "            results.append({\n",
    "                'text': chunk.page_content,\n",
    "                'score': float(score),\n",
    "                'chunk_id': int(idx),\n",
    "                'start_pos': chunk.metadata.get('start_index', 0) if hasattr(chunk, 'metadata') else 0\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# def generate_answer(query, context_chunks, max_new_tokens=350):\n",
    "#     \"\"\"Generate answer using retrieved context\"\"\"\n",
    "#     # Combine context from relevant chunks\n",
    "#     context_parts = []\n",
    "#     for i, chunk in enumerate(context_chunks):\n",
    "#         context_parts.append(f\"[Section {i+1}]\\n{chunk['text']}\")\n",
    "\n",
    "#     combined_context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "#     # Create optimized prompt for university handbook\n",
    "#     prompt = f\"\"\"<s>[INST] You are a university student advisor with access to the official student handbook. Answer the student's question accurately using only the provided handbook sections.\n",
    "\n",
    "# HANDBOOK SECTIONS:\n",
    "# {combined_context}\n",
    "\n",
    "# STUDENT QUESTION: {query}\n",
    "\n",
    "# Provide a clear, helpful answer based on the handbook information above. If the handbook doesn't contain enough information, say so. Be specific about policies, procedures, and requirements. [/INST]\"\"\"\n",
    "\n",
    "#     # Tokenize and generate\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=3072)\n",
    "#     inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=max_new_tokens,\n",
    "#             temperature=0.2,  # Low for factual accuracy\n",
    "#             do_sample=True,\n",
    "#             top_p=0.9,\n",
    "#             repetition_penalty=1.1,\n",
    "#             pad_token_id=tokenizer.eos_token_id,\n",
    "#             eos_token_id=tokenizer.eos_token_id\n",
    "#         )\n",
    "\n",
    "#     # Extract generated answer\n",
    "#     response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     answer_start = response.find(\"[/INST]\") + len(\"[/INST]\")\n",
    "#     answer = response[answer_start:].strip()\n",
    "\n",
    "#     return answer\n",
    "\n",
    "\n",
    "def generate_answer(query, context_chunks, max_new_tokens=350):\n",
    "\n",
    "    if not context_chunks:\n",
    "        # Handle case where no context is retrieved\n",
    "        combined_context = \"No information found in the handbook.\"\n",
    "    else:\n",
    "        # --- MODIFICATION 1: Re-ranking and XML-style Tags ---\n",
    "        # ASSUMPTION: context_chunks is a list of dicts, e.g., [{'text': ...}, ...],\n",
    "        # pre-sorted from MOST relevant [0] to LEAST relevant [-1].\n",
    "\n",
    "        best_chunk = context_chunks[0]  # The most relevant chunk\n",
    "        other_chunks = context_chunks[1:] # All other (less relevant) chunks\n",
    "\n",
    "        # Reverse the 'other' chunks so the absolute least relevant is first\n",
    "        other_chunks.reverse() \n",
    "\n",
    "        context_parts = []\n",
    "        \n",
    "        # 1. Add the less relevant chunks first\n",
    "        for i, chunk in enumerate(other_chunks):\n",
    "            # Using XML-style tags for better separation\n",
    "            context_parts.append(f\"<HANDBOOK_SECTION_{i+1}>\\n{chunk['text']}\\n</HANDBOOK_SECTION_{i+1}>\")\n",
    "\n",
    "        # 2. Add the MOST relevant chunk at the very end of the context\n",
    "        context_parts.append(f\"<HANDBOOK_SECTION_MOST_RELEVANT>\\n{best_chunk['text']}\\n</HANDBOOK_SECTION_MOST_RELEVANT>\")\n",
    "        \n",
    "        combined_context = \"\\n\\n\".join(context_parts)\n",
    "        # --- End of Modification 1 ---\n",
    "\n",
    "    # Create optimized prompt (your template is already excellent)\n",
    "    prompt = f\"\"\"<s>[INST] You are Amang Bot (Ambot) a university student advisor. Answer the student's question accurately using only the provided sections below.\n",
    "\n",
    "HANDBOOK SECTIONS:\n",
    "{combined_context}\n",
    "\n",
    "STUDENT QUESTION: {query}\n",
    "\n",
    "Provide a clear, helpful answer based on the information above. If the handbook doesn't contain enough information, say so. Be specific about policies, procedures, and requirements. [/INST]\"\"\"\n",
    "\n",
    "\n",
    "    untruncated_inputs = tokenizer(prompt)\n",
    "    original_length = len(untruncated_inputs['input_ids'])\n",
    "    # --- End Debug ---\n",
    "\n",
    "    # Tokenize and generate (Your original code)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=3072)\n",
    "    \n",
    "    # --- MODIFICATION 2: Store input length for better decoding ---\n",
    "    input_length = inputs['input_ids'].shape[1] \n",
    "    \n",
    "    # --- DEBUG: Print the comparison ---\n",
    "    print(f\"--- TRUNCATION REPORT ---\")\n",
    "    print(f\"Original token length: {original_length}\")\n",
    "    print(f\"Truncated token length: {input_length} (Max: 3072)\")\n",
    "    if original_length > input_length:\n",
    "        print(\"WARNING: The prompt was truncated.\")\n",
    "    else:\n",
    "        print(\"INFO: The prompt was not truncated.\")\n",
    "    print(\"-------------------------\\n\")\n",
    "    \n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=3072)\n",
    "    \n",
    "    # --- MODIFICATION 2: Store input length for better decoding ---\n",
    "    input_length = inputs['input_ids'].shape[1] \n",
    "    # --- End of Modification 2 ---\n",
    "    \n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.2,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # --- MODIFICATION 3: More Robust Decoding ---\n",
    "    # Decode only the *newly generated tokens* by slicing the output tensor\n",
    "    # This avoids any string matching for \"[/INST]\"\n",
    "    new_tokens = outputs[0][input_length:]\n",
    "    answer = tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
    "    # --- End of Modification 3 ---\n",
    "\n",
    "    print(answer)\n",
    "    return answer\n",
    "\n",
    "# --- EXAMPLE USAGE ---\n",
    "# (Assuming you have your retrieval logic first)\n",
    "\n",
    "# 1. Your retrieval system gets the chunks, sorted by relevance (best first)\n",
    "# retrieved_chunks = [\n",
    "#     {'text': \"The policy for late submission is a 10% penalty per day. (This is the best chunk)\"},\n",
    "#     {'text': \"The add/drop period is in the first week. (Less relevant)\"},\n",
    "#     {'text': \"General academic regulations. (Least relevant)\"}\n",
    "# ]\n",
    "\n",
    "# 2. Pass the query and the sorted chunks to the function\n",
    "# student_query = \"What happens if I submit my assignment late?\"\n",
    "# answer = generate_answer(student_query, retrieved_chunks)\n",
    "# print(answer)\n",
    "\n",
    "def ask_handbook(question, top_k=5, show_sources=True):\n",
    "    \"\"\"Complete RAG pipeline for handbook queries\"\"\"\n",
    "    print(f\"\\n‚ùì Question: {question}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Retrieve relevant sections\n",
    "    relevant_chunks = retrieve_relevant_chunks(question, top_k)\n",
    "\n",
    "    if not relevant_chunks:\n",
    "        print(\"‚ùå No relevant information found in handbook\")\n",
    "        return None\n",
    "\n",
    "    if show_sources:\n",
    "        print(\"üìö Found relevant handbook sections:\")\n",
    "        for i, chunk in enumerate(relevant_chunks):\n",
    "            print(f\"\\nüìÑ Section {i+1} (Relevance: {chunk['score']:.3f})\")\n",
    "            preview = chunk['text'][:200].replace('\\n', ' ')\n",
    "            print(f\"   {preview}...\")\n",
    "\n",
    "    # Generate answer\n",
    "    print(\"\\nü§î Generating answer...\")\n",
    "    answer = generate_answer(question, relevant_chunks)\n",
    "\n",
    "    print(f\"\\nüí° Answer:\")\n",
    "    print(answer)\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "    return {\n",
    "        'question': question,\n",
    "        'answer': answer,\n",
    "        'sources': relevant_chunks,\n",
    "        'num_sources': len(relevant_chunks)\n",
    "    }\n",
    "\n",
    "# Test the system\n",
    "print(\"\\n\\nüöÄ RAG System Ready!\")\n",
    "print(\"Testing with university-specific questions...\")\n",
    "\n",
    "# Sample test questions for university handbook\n",
    "test_questions = [\n",
    "    \"What are the graduation requirements?\",\n",
    "    \"How do I withdraw from a course?\",\n",
    "    \"What is the academic probation policy?\",\n",
    "    \"What happens if I'm caught cheating?\",\n",
    "    \"How do I change my major?\"\n",
    "]\n",
    "\n",
    "# Run a test query\n",
    "# test_result = ask_handbook(test_questions[0])\n",
    "\n",
    "# Interactive query function\n",
    "def interactive_mode():\n",
    "    \"\"\"Interactive mode for asking questions\"\"\"\n",
    "    print(\"\\nüéì Interactive University Handbook Assistant\")\n",
    "    print(\"Type 'quit' to exit\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    while True:\n",
    "        question = input(\"\\n‚ùì Your question: \").strip()\n",
    "\n",
    "        if question.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "\n",
    "        if not question:\n",
    "            print(\"Please enter a question!\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ask_handbook(question)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "# Uncomment to start interactive mode\n",
    "# interactive_mode()\n",
    "\n",
    "print(\"\\nüìã System Summary:\")\n",
    "print(f\"   üìö Processed: {len(chunks):,} semantic chunks\")\n",
    "print(f\"   üîç Embeddings: {len(all_embeddings):,} vectors\")\n",
    "print(f\"   ü§ñ Model: {model_name}\")\n",
    "print(f\"   üíæ Ready for queries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NWU8gAYsanLa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéì Interactive University Handbook Assistant\n",
      "Type 'quit' to exit\n",
      "--------------------------------------------------\n",
      "\n",
      "‚ùì Question: I was sick and missed my midterms. What should I do to get an excused absence?\n",
      "======================================================================\n",
      "üìö Found relevant handbook sections:\n",
      "\n",
      "üìÑ Section 1 (Relevance: 0.455)\n",
      "   2009)   ## SECTION 5. ATTENDANCE   5.1 Students are required to attend all classes starting with the first meeting of every class. 5.2 Non-attendance in any required class or academic activity constit...\n",
      "\n",
      "üìÑ Section 2 (Relevance: 0.449)\n",
      "   For Re-Admission of students who would like to continue their program after taking the leave of absence, the following are needed:   1. Copy of Approved Leave of Absence; 2. Evaluation Record Form fro...\n",
      "\n",
      "üìÑ Section 3 (Relevance: 0.415)\n",
      "   the first 20 minutes for a two-hour class; - 5.1.3. the first 15 minutes for a one-hour-and-a-half class; and - 5.1.4. the first 10 minutes for a one-hour class. 5.4 A student is considered late or ta...\n",
      "\n",
      "üìÑ Section 4 (Relevance: 0.396)\n",
      "   * d. Failure to enroll... * e....\n",
      "\n",
      "üìÑ Section 5 (Relevance: 0.387)\n",
      "   Did not commit any infraction ranging from serious to very serious offense as stated in the Student Handbook....\n",
      "\n",
      "ü§î Generating answer...\n",
      "--- TRUNCATION REPORT ---\n",
      "Original token length: 3741\n",
      "Truncated token length: 3072 (Max: 3072)\n",
      "WARNING: The prompt was truncated.\n",
      "-------------------------\n",
      "\n",
      "4 Payment of tuition and fees, and\n",
      "1.1.5 Issuance of the Student Identification Card.\n",
      "\n",
      "\n",
      "1.2 Cross enrollment of students shall be allowed only in the following instances:\n",
      "\n",
      "\n",
      "1.2.1 When the student is unable to fulfill the requirements for graduation in the current semester,\n",
      "1.2.2 When the student is unable to complete the required number of credits for graduation in the current semester,\n",
      "1.2.3 When the student wishes to pursue a different field of study,\n",
      "1.2.4 When the student wishes to transfer to another school or college,\n",
      "1.2.5 When the student wishes to pursue a graduate degree.\n",
      "\n",
      "\n",
      "1.3 Cross enrollment shall be approved by the College Dean/Campus Administrator.\n",
      "\n",
      "\n",
      "1.4 Cross enrollment shall be subject to the following conditions:\n",
      "\n",
      "\n",
      "1.4.1 The student must have a minimum GPA of 2.00 in the previous semester,\n",
      "1.4.2 The student must have completed all the required courses for graduation in the current semester,\n",
      "1.4.3 The student must have paid all outstanding debts to the school,\n",
      "1.4.4 The student must have obtained the approval of the College Dean/Campus Administrator,\n",
      "1.4.5 The student must have obtained the approval of the College/School/Department Head,\n",
      "1.4.6 The student must have obtained the approval of the Registrar's Office,\n",
      "1.4.7 The student must have obtained the approval of the Admissions Committee,\n",
      "1\n",
      "\n",
      "üí° Answer:\n",
      "4 Payment of tuition and fees, and\n",
      "1.1.5 Issuance of the Student Identification Card.\n",
      "\n",
      "\n",
      "1.2 Cross enrollment of students shall be allowed only in the following instances:\n",
      "\n",
      "\n",
      "1.2.1 When the student is unable to fulfill the requirements for graduation in the current semester,\n",
      "1.2.2 When the student is unable to complete the required number of credits for graduation in the current semester,\n",
      "1.2.3 When the student wishes to pursue a different field of study,\n",
      "1.2.4 When the student wishes to transfer to another school or college,\n",
      "1.2.5 When the student wishes to pursue a graduate degree.\n",
      "\n",
      "\n",
      "1.3 Cross enrollment shall be approved by the College Dean/Campus Administrator.\n",
      "\n",
      "\n",
      "1.4 Cross enrollment shall be subject to the following conditions:\n",
      "\n",
      "\n",
      "1.4.1 The student must have a minimum GPA of 2.00 in the previous semester,\n",
      "1.4.2 The student must have completed all the required courses for graduation in the current semester,\n",
      "1.4.3 The student must have paid all outstanding debts to the school,\n",
      "1.4.4 The student must have obtained the approval of the College Dean/Campus Administrator,\n",
      "1.4.5 The student must have obtained the approval of the College/School/Department Head,\n",
      "1.4.6 The student must have obtained the approval of the Registrar's Office,\n",
      "1.4.7 The student must have obtained the approval of the Admissions Committee,\n",
      "1\n",
      "\n",
      "======================================================================\n",
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-IVr9nJbuwD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Workflow with Test Dataset\n",
    "\n",
    "This section will run all questions from Test.json through the RAG pipeline and save results to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Loaded 100 test questions\n",
      "üìä Categories: {'scenario', 'direct', 'unanswerable', 'adversarial', 'paraphrased'}\n",
      "üìä Difficulty levels: {'hard', 'easy', 'medium'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Load test questions\n",
    "with open('../Test/Test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"üìã Loaded {len(test_data)} test questions\")\n",
    "print(f\"üìä Categories: {set(q['category'] for q in test_data)}\")\n",
    "print(f\"üìä Difficulty levels: {set(q['difficulty'] for q in test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rag_pipeline(test_data, top_k=5, output_file='rag_test_results.csv'):\n",
    "    \"\"\"\n",
    "    Run RAG pipeline on all test questions and save results to CSV\n",
    "    \n",
    "    Args:\n",
    "        test_data: List of test questions with expected answers\n",
    "        top_k: Number of chunks to retrieve\n",
    "        output_file: Output CSV filename\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\nüöÄ Starting RAG Pipeline Test\")\n",
    "    print(f\"üìù Testing {len(test_data)} questions...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, test_item in enumerate(test_data):\n",
    "        question = test_item['question']\n",
    "        expected_answer = test_item['answer']\n",
    "        difficulty = test_item['difficulty']\n",
    "        category = test_item['category']\n",
    "        \n",
    "        print(f\"\\n[{i+1}/{len(test_data)}] Processing: {question[:60]}...\")\n",
    "        \n",
    "        try:\n",
    "            # Start timing\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Retrieve relevant chunks\n",
    "            relevant_chunks = retrieve_relevant_chunks(question, top_k)\n",
    "            \n",
    "            # Generate answer\n",
    "            if relevant_chunks:\n",
    "                generated_answer = generate_answer(question, relevant_chunks, max_new_tokens=350)\n",
    "                \n",
    "                # Calculate average relevance score\n",
    "                avg_score = sum(chunk['score'] for chunk in relevant_chunks) / len(relevant_chunks)\n",
    "                top_score = relevant_chunks[0]['score'] if relevant_chunks else 0\n",
    "                \n",
    "                # Get chunk IDs\n",
    "                chunk_ids = [chunk['chunk_id'] for chunk in relevant_chunks]\n",
    "            else:\n",
    "                generated_answer = \"NO RELEVANT CHUNKS FOUND\"\n",
    "                avg_score = 0\n",
    "                top_score = 0\n",
    "                chunk_ids = []\n",
    "            \n",
    "            # End timing\n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Store result\n",
    "            result = {\n",
    "                'question_number': i + 1,\n",
    "                'question': question,\n",
    "                'expected_answer': expected_answer,\n",
    "                'generated_answer': generated_answer,\n",
    "                'difficulty': difficulty,\n",
    "                'category': category,\n",
    "                'processing_time_sec': round(processing_time, 2),\n",
    "                'top_relevance_score': round(top_score, 4),\n",
    "                'avg_relevance_score': round(avg_score, 4),\n",
    "                'num_chunks_retrieved': len(relevant_chunks),\n",
    "                'chunk_ids': str(chunk_ids)\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            print(f\"‚úÖ Completed in {processing_time:.2f}s (Relevance: {top_score:.3f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "            result = {\n",
    "                'question_number': i + 1,\n",
    "                'question': question,\n",
    "                'expected_answer': expected_answer,\n",
    "                'generated_answer': f\"ERROR: {str(e)}\",\n",
    "                'difficulty': difficulty,\n",
    "                'category': category,\n",
    "                'processing_time_sec': 0,\n",
    "                'top_relevance_score': 0,\n",
    "                'avg_relevance_score': 0,\n",
    "                'num_chunks_retrieved': 0,\n",
    "                'chunk_ids': '[]'\n",
    "            }\n",
    "            results.append(result)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"rag_test_results_{timestamp}.csv\"\n",
    "    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"‚úÖ Testing Complete!\")\n",
    "    print(f\"üìä Total questions: {len(results)}\")\n",
    "    print(f\"üíæ Results saved to: {output_filename}\")\n",
    "    print(f\"‚è±Ô∏è  Total time: {df['processing_time_sec'].sum():.2f}s\")\n",
    "    print(f\"üìà Average processing time: {df['processing_time_sec'].mean():.2f}s per question\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nüìä Summary by Category:\")\n",
    "    category_summary = df.groupby('category').agg({\n",
    "        'question': 'count',\n",
    "        'processing_time_sec': 'mean',\n",
    "        'top_relevance_score': 'mean'\n",
    "    }).round(2)\n",
    "    print(category_summary)\n",
    "    \n",
    "    print(\"\\nüìä Summary by Difficulty:\")\n",
    "    difficulty_summary = df.groupby('difficulty').agg({\n",
    "        'question': 'count',\n",
    "        'processing_time_sec': 'mean',\n",
    "        'top_relevance_score': 'mean'\n",
    "    }).round(2)\n",
    "    print(difficulty_summary)\n",
    "    \n",
    "    return df, output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting RAG Pipeline Test\n",
      "üìù Testing 100 questions...\n",
      "================================================================================\n",
      "\n",
      "[1/100] Processing: What documents do I need to submit to apply as a freshman?...\n",
      "‚úÖ Completed in 14.51s (Relevance: 0.536)\n",
      "\n",
      "[2/100] Processing: I'm a transferee from another uni, what papers do I need?...\n",
      "‚úÖ Completed in 10.50s (Relevance: 0.510)\n",
      "\n",
      "[3/100] Processing: My EARISTCAT score for BS Civil Engineering was 82%. Did I g...\n",
      "‚úÖ Completed in 10.38s (Relevance: 0.467)\n",
      "\n",
      "[4/100] Processing: Admission is first-come-first-served, right? So my EARISTCAT...\n",
      "‚úÖ Completed in 79.45s (Relevance: 0.600)\n",
      "\n",
      "[5/100] Processing: What's the deadline for freshman applications for the next s...\n",
      "‚úÖ Completed in 6.47s (Relevance: 0.489)\n",
      "\n",
      "[6/100] Processing: I'm applying for BS Architecture. Is there any other test be...\n",
      "‚úÖ Completed in 11.40s (Relevance: 0.565)\n",
      "\n",
      "[7/100] Processing: What's the maximum number of units I can enroll in per semes...\n",
      "‚úÖ Completed in 15.30s (Relevance: 0.629)\n",
      "\n",
      "[8/100] Processing: I'm a regular student, can I enroll in just 6 units this sem...\n",
      "‚úÖ Completed in 9.55s (Relevance: 0.604)\n",
      "\n",
      "[9/100] Processing: Can I enroll in two different colleges at EARIST at the same...\n",
      "‚úÖ Completed in 11.86s (Relevance: 0.475)\n",
      "\n",
      "[10/100] Processing: How much is the tuition fee per unit?...\n",
      "‚úÖ Completed in 10.75s (Relevance: 0.642)\n",
      "\n",
      "[11/100] Processing: My required subject isn't offered this sem. Can I just take ...\n",
      "‚úÖ Completed in 12.62s (Relevance: 0.398)\n",
      "\n",
      "[12/100] Processing: What's the official process for dropping a subject?...\n",
      "‚úÖ Completed in 5.12s (Relevance: 0.410)\n",
      "\n",
      "[13/100] Processing: I failed my 'Intro to Programming' major. Can I just substit...\n",
      "‚úÖ Completed in 29.00s (Relevance: 0.375)\n",
      "\n",
      "[14/100] Processing: How many absences am I allowed before I get dropped from a c...\n",
      "‚úÖ Completed in 69.89s (Relevance: 0.654)\n",
      "\n",
      "[15/100] Processing: How late can I be to class before I'm marked absent?...\n",
      "‚úÖ Completed in 42.97s (Relevance: 0.680)\n",
      "\n",
      "[16/100] Processing: I've been late three times. Does that equal one absence?...\n",
      "‚úÖ Completed in 50.45s (Relevance: 0.535)\n",
      "\n",
      "[17/100] Processing: I was sick and missed my midterms. What should I do to get a...\n",
      "‚úÖ Completed in 88.19s (Relevance: 0.455)\n",
      "\n",
      "[18/100] Processing: What's the minimum passing grade?...\n",
      "‚úÖ Completed in 16.21s (Relevance: 0.610)\n",
      "\n",
      "[19/100] Processing: I got a 2.50 in a subject. What does that mean?...\n",
      "‚úÖ Completed in 14.80s (Relevance: 0.490)\n",
      "\n",
      "[20/100] Processing: My prof gave me an INC last sem. How long do I have to fix i...\n",
      "‚úÖ Completed in 25.06s (Relevance: 0.416)\n",
      "\n",
      "[21/100] Processing: I passed my class with a 3.0 but I want to improve it. Can I...\n",
      "‚úÖ Completed in 30.77s (Relevance: 0.376)\n",
      "\n",
      "[22/100] Processing: What's the grading breakdown? like how many percent for quiz...\n",
      "‚úÖ Completed in 16.16s (Relevance: 0.563)\n",
      "\n",
      "[23/100] Processing: My prof, who gave me an INC, is on leave and I can't contact...\n",
      "‚úÖ Completed in 9.28s (Relevance: 0.368)\n",
      "\n",
      "[24/100] Processing: What happens if I fail 3 subjects in one semester?...\n",
      "‚úÖ Completed in 8.14s (Relevance: 0.529)\n",
      "\n",
      "[25/100] Processing: My friend is on academic probation. How does he get out of i...\n",
      "‚úÖ Completed in 18.19s (Relevance: 0.542)\n",
      "\n",
      "[26/100] Processing: I'm a freshman and I failed 2 subjects in my first sem. Am I...\n",
      "‚úÖ Completed in 17.24s (Relevance: 0.445)\n",
      "\n",
      "[27/100] Processing: This is my third time taking the same subject. What happens ...\n",
      "‚úÖ Completed in 7.56s (Relevance: 0.587)\n",
      "\n",
      "[28/100] Processing: I failed 2 subjects, and I also have an INC. Does the INC co...\n",
      "‚úÖ Completed in 13.46s (Relevance: 0.555)\n",
      "\n",
      "[29/100] Processing: What's the maximum time I can take for a leave of absence (L...\n",
      "‚úÖ Completed in 10.45s (Relevance: 0.545)\n",
      "\n",
      "[30/100] Processing: I'm in a 4-year degree program. What's the maximum number of...\n",
      "‚úÖ Completed in 16.34s (Relevance: 0.436)\n",
      "\n",
      "[31/100] Processing: I'm a working student in a 4-year course. Do I also have a 5...\n",
      "‚úÖ Completed in 17.47s (Relevance: 0.532)\n",
      "\n",
      "[32/100] Processing: What's the GWA range to graduate Cum Laude?...\n",
      "‚úÖ Completed in 22.30s (Relevance: 0.610)\n",
      "\n",
      "[33/100] Processing: I'm a transferee. Can I still graduate with honors?...\n",
      "‚úÖ Completed in 42.86s (Relevance: 0.568)\n",
      "\n",
      "[34/100] Processing: I'm aiming for Cum Laude and my GWA is 1.7. But I failed one...\n",
      "‚úÖ Completed in 27.92s (Relevance: 0.492)\n",
      "\n",
      "[35/100] Processing: For graduating with honors, do they include PE and NSTP grad...\n",
      "‚úÖ Completed in 68.37s (Relevance: 0.684)\n",
      "\n",
      "[36/100] Processing: What is the 'Student Assistance' program?...\n",
      "‚úÖ Completed in 9.51s (Relevance: 0.520)\n",
      "\n",
      "[37/100] Processing: What are the requirements to become a student assistant (SA)...\n",
      "‚úÖ Completed in 14.61s (Relevance: 0.539)\n",
      "\n",
      "[38/100] Processing: Can I be a recipient of the Tulong Dunong Program and anothe...\n",
      "‚úÖ Completed in 19.62s (Relevance: 0.602)\n",
      "\n",
      "[39/100] Processing: Where is the office for submitting DOST scholarship applicat...\n",
      "‚úÖ Completed in 3.65s (Relevance: 0.577)\n",
      "\n",
      "[40/100] Processing: My father works at EARIST. Can I get a scholarship?...\n",
      "‚úÖ Completed in 9.16s (Relevance: 0.517)\n",
      "\n",
      "[41/100] Processing: What's the required haircut for guys?...\n",
      "‚úÖ Completed in 4.12s (Relevance: 0.600)\n",
      "\n",
      "[42/100] Processing: When are we allowed to wear 'civilian' clothes or non-unifor...\n",
      "‚úÖ Completed in 19.22s (Relevance: 0.490)\n",
      "\n",
      "[43/100] Processing: I lost my ID again. This is the second time. What's the pena...\n",
      "‚úÖ Completed in 9.81s (Relevance: 0.479)\n",
      "\n",
      "[44/100] Processing: I lost my ID for the third time... is that still just a mino...\n",
      "‚úÖ Completed in 5.31s (Relevance: 0.488)\n",
      "\n",
      "[45/100] Processing: What does the school uniform look like? What's the color?...\n",
      "‚úÖ Completed in 8.95s (Relevance: 0.439)\n",
      "\n",
      "[46/100] Processing: Are guys allowed to wear earrings on campus?...\n",
      "‚úÖ Completed in 7.57s (Relevance: 0.614)\n",
      "\n",
      "[47/100] Processing: My job requires me to have long hair, but the handbook says ...\n",
      "‚úÖ Completed in 8.64s (Relevance: 0.465)\n",
      "\n",
      "[48/100] Processing: Is cheating on an exam a major or minor offense?...\n",
      "‚úÖ Completed in 2.18s (Relevance: 0.484)\n",
      "\n",
      "[49/100] Processing: What's the penalty for getting caught copying on a quiz?...\n",
      "‚úÖ Completed in 6.69s (Relevance: 0.398)\n",
      "\n",
      "[50/100] Processing: This is confusing. Is 'cheating' a major offense or a minor ...\n",
      "‚úÖ Completed in 8.43s (Relevance: 0.509)\n",
      "\n",
      "[51/100] Processing: Am I allowed to bring or drink alcohol on campus?...\n",
      "‚úÖ Completed in 4.81s (Relevance: 0.576)\n",
      "\n",
      "[52/100] Processing: Is it okay if I join a student org that isn't officially rec...\n",
      "‚úÖ Completed in 70.44s (Relevance: 0.587)\n",
      "\n",
      "[53/100] Processing: What is the school's policy on smoking or vaping?...\n",
      "‚úÖ Completed in 7.27s (Relevance: 0.543)\n",
      "\n",
      "[54/100] Processing: I recorded my professor's Zoom class and posted it on social...\n",
      "‚úÖ Completed in 16.19s (Relevance: 0.492)\n",
      "\n",
      "[55/100] Processing: How much is the fine if I get caught littering?...\n",
      "‚úÖ Completed in 7.09s (Relevance: 0.340)\n",
      "\n",
      "[56/100] Processing: My org has an 'initiation'. Is that considered 'hazing' and ...\n",
      "‚úÖ Completed in 29.77s (Relevance: 0.454)\n",
      "\n",
      "[57/100] Processing: What's the most severe penalty the school can give a student...\n",
      "‚úÖ Completed in 10.88s (Relevance: 0.690)\n",
      "\n",
      "[58/100] Processing: What's the difference between being 'dismissed' and 'expelle...\n",
      "‚úÖ Completed in 16.94s (Relevance: 0.714)\n",
      "\n",
      "[59/100] Processing: Does EARIST have a guidance counselor I can talk to?...\n",
      "‚úÖ Completed in 10.02s (Relevance: 0.345)\n",
      "\n",
      "[60/100] Processing: I'm graduating soon. Does the school have programs to help m...\n",
      "‚úÖ Completed in 15.22s (Relevance: 0.298)\n",
      "\n",
      "[61/100] Processing: What services does the school clinic offer?...\n",
      "‚úÖ Completed in 15.29s (Relevance: 0.555)\n",
      "\n",
      "[62/100] Processing: What time does the school clinic open and close?...\n",
      "‚úÖ Completed in 69.23s (Relevance: 0.372)\n",
      "\n",
      "[63/100] Processing: I left my laptop in a classroom. Is the school security offi...\n",
      "‚úÖ Completed in 27.28s (Relevance: 0.431)\n",
      "\n",
      "[64/100] Processing: What benefits do student-athletes get?...\n",
      "‚úÖ Completed in 16.99s (Relevance: 0.646)\n",
      "\n",
      "[65/100] Processing: I'm on the varsity team, so my grades don't matter as much, ...\n",
      "‚úÖ Completed in 15.48s (Relevance: 0.395)\n",
      "\n",
      "[66/100] Processing: Is there a gym that any student can use for working out, eve...\n",
      "‚úÖ Completed in 10.80s (Relevance: 0.317)\n",
      "\n",
      "[67/100] Processing: What kind of support does EARIST offer for students with dis...\n",
      "‚úÖ Completed in 27.32s (Relevance: 0.670)\n",
      "\n",
      "[68/100] Processing: How long does a student org's accreditation last?...\n",
      "‚úÖ Completed in 20.22s (Relevance: 0.646)\n",
      "\n",
      "[69/100] Processing: My friends and I want to start a new org. What's the process...\n",
      "‚úÖ Completed in 32.67s (Relevance: 0.423)\n",
      "\n",
      "[70/100] Processing: How much can my college-based org charge for a membership fe...\n",
      "‚úÖ Completed in 7.73s (Relevance: 0.561)\n",
      "\n",
      "[71/100] Processing: My student org wants to hold an event off-campus. What speci...\n",
      "‚úÖ Completed in 69.85s (Relevance: 0.509)\n",
      "\n",
      "[72/100] Processing: Our faculty adviser is busy and can't come to our off-campus...\n",
      "‚úÖ Completed in 21.66s (Relevance: 0.376)\n",
      "\n",
      "[73/100] Processing: How much is the budget for the Institute Student Government ...\n",
      "‚úÖ Completed in 15.33s (Relevance: 0.604)\n",
      "\n",
      "[74/100] Processing: My org has a bank account. Who are the required signatories ...\n",
      "‚úÖ Completed in 17.91s (Relevance: 0.628)\n",
      "\n",
      "[75/100] Processing: What are the requirements to be a faculty adviser for a stud...\n",
      "‚úÖ Completed in 30.94s (Relevance: 0.728)\n",
      "\n",
      "[76/100] Processing: Where does the student publication get its funding?...\n",
      "‚úÖ Completed in 13.98s (Relevance: 0.484)\n",
      "\n",
      "[77/100] Processing: I made a poster for my org. Can I just post it anywhere on c...\n",
      "‚úÖ Completed in 8.00s (Relevance: 0.451)\n",
      "\n",
      "[78/100] Processing: Can the school administration censor our student paper if we...\n",
      "‚úÖ Completed in 74.06s (Relevance: 0.569)\n",
      "\n",
      "[79/100] Processing: How much is the student publication fee that's collected dur...\n",
      "‚úÖ Completed in 4.14s (Relevance: 0.507)\n",
      "\n",
      "[80/100] Processing: What college is BS Criminology under?...\n",
      "‚úÖ Completed in 75.51s (Relevance: 0.556)\n",
      "\n",
      "[81/100] Processing: Does EARIST have an MBA program?...\n",
      "‚úÖ Completed in 8.29s (Relevance: 0.504)\n",
      "\n",
      "[82/100] Processing: What was the school's name before it became EARIST?...\n",
      "‚úÖ Completed in 2.99s (Relevance: 0.543)\n",
      "\n",
      "[83/100] Processing: Can I take Aerospace Engineering at EARIST?...\n",
      "‚úÖ Completed in 10.42s (Relevance: 0.437)\n",
      "\n",
      "[84/100] Processing: Who is the president of EARIST?...\n",
      "‚úÖ Completed in 2.04s (Relevance: 0.712)\n",
      "\n",
      "[85/100] Processing: I want to apply for BS Information Technology. Which college...\n",
      "‚úÖ Completed in 19.20s (Relevance: 0.475)\n",
      "\n",
      "[86/100] Processing: Are the courses offered in EARIST Cavite the same as the one...\n",
      "‚úÖ Completed in 78.72s (Relevance: 0.570)\n",
      "\n",
      "[87/100] Processing: What's the email address for the Dean of the College of Engi...\n",
      "‚úÖ Completed in 12.63s (Relevance: 0.509)\n",
      "\n",
      "[88/100] Processing: Who is the dean of CAS?...\n",
      "‚úÖ Completed in 6.44s (Relevance: 0.579)\n",
      "\n",
      "[89/100] Processing: Does the school have a swimming pool?...\n",
      "‚úÖ Completed in 6.44s (Relevance: 0.338)\n",
      "\n",
      "[90/100] Processing: What are the library's opening and closing hours?...\n",
      "‚úÖ Completed in 2.30s (Relevance: 0.394)\n",
      "\n",
      "[91/100] Processing: What is the official vision statement of EARIST?...\n",
      "‚úÖ Completed in 3.13s (Relevance: 0.651)\n",
      "\n",
      "[92/100] Processing: What is EARIST's mission?...\n",
      "‚úÖ Completed in 14.68s (Relevance: 0.718)\n",
      "\n",
      "[93/100] Processing: I'm currently enrolled in the Cavite campus. Is it possible ...\n",
      "‚úÖ Completed in 38.53s (Relevance: 0.650)\n",
      "\n",
      "[94/100] Processing: I'm taking my OJT this semester. Can I also enroll in a majo...\n",
      "‚úÖ Completed in 19.39s (Relevance: 0.486)\n",
      "\n",
      "[95/100] Processing: Is there free Wi-Fi for students on campus?...\n",
      "‚úÖ Completed in 11.58s (Relevance: 0.350)\n",
      "\n",
      "[96/100] Processing: I want to run for ISG President. My GWA is 2.75 and I have n...\n",
      "‚úÖ Completed in 9.79s (Relevance: 0.525)\n",
      "\n",
      "[97/100] Processing: I want to run for student council. My GWA is excellent (2.0)...\n",
      "‚úÖ Completed in 10.59s (Relevance: 0.397)\n",
      "\n",
      "[98/100] Processing: Can students bring a car to school? Is there a parking lot f...\n",
      "‚úÖ Completed in 19.91s (Relevance: 0.474)\n",
      "\n",
      "[99/100] Processing: Does EARIST have a study abroad program?...\n",
      "‚úÖ Completed in 12.12s (Relevance: 0.596)\n",
      "\n",
      "[100/100] Processing: My organization wants to sell t-shirts with the EARIST logo ...\n",
      "‚úÖ Completed in 27.31s (Relevance: 0.603)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Testing Complete!\n",
      "üìä Total questions: 100\n",
      "üíæ Results saved to: rag_test_results_20251102_222414.csv\n",
      "‚è±Ô∏è  Total time: 2077.98s\n",
      "üìà Average processing time: 20.78s per question\n",
      "\n",
      "üìä Summary by Category:\n",
      "              question  processing_time_sec  top_relevance_score\n",
      "category                                                        \n",
      "adversarial         17                32.64                 0.51\n",
      "direct              26                16.00                 0.57\n",
      "paraphrased         17                19.69                 0.55\n",
      "scenario            24                23.19                 0.50\n",
      "unanswerable        16                13.49                 0.46\n",
      "\n",
      "üìä Summary by Difficulty:\n",
      "            question  processing_time_sec  top_relevance_score\n",
      "difficulty                                                    \n",
      "easy              52                15.79                 0.53\n",
      "hard              12                21.17                 0.49\n",
      "medium            36                27.86                 0.52\n",
      "\n",
      "üìÑ Preview of results:\n",
      "   question_number      category difficulty  top_relevance_score  \\\n",
      "0                1        direct       easy               0.5364   \n",
      "1                2   paraphrased       easy               0.5097   \n",
      "2                3      scenario     medium               0.4672   \n",
      "3                4   adversarial     medium               0.6003   \n",
      "4                5  unanswerable       easy               0.4891   \n",
      "5                6      scenario     medium               0.5652   \n",
      "6                7        direct       easy               0.6293   \n",
      "7                8      scenario     medium               0.6045   \n",
      "8                9   adversarial     medium               0.4750   \n",
      "9               10  unanswerable       easy               0.6421   \n",
      "\n",
      "   processing_time_sec  \n",
      "0                14.51  \n",
      "1                10.50  \n",
      "2                10.38  \n",
      "3                79.45  \n",
      "4                 6.47  \n",
      "5                11.40  \n",
      "6                15.30  \n",
      "7                 9.55  \n",
      "8                11.86  \n",
      "9                10.75  \n"
     ]
    }
   ],
   "source": [
    "# Run the test pipeline\n",
    "results_df, output_file = test_rag_pipeline(test_data, top_k=5)\n",
    "\n",
    "print(f\"\\nüìÑ Preview of results:\")\n",
    "print(results_df[['question_number', 'category', 'difficulty', 'top_relevance_score', 'processing_time_sec']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: View Individual Results\n",
    "\n",
    "You can examine specific questions and their generated answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a specific result\n",
    "question_num = 3  # Change this to view different questions\n",
    "\n",
    "result = results_df.iloc[question_num - 1]\n",
    "\n",
    "print(f\"Question #{result['question_number']}\")\n",
    "print(f\"Category: {result['category']} | Difficulty: {result['difficulty']}\")\n",
    "print(f\"Relevance Score: {result['top_relevance_score']}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\n‚ùì QUESTION:\\n{result['question']}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nüìñ EXPECTED ANSWER:\\n{result['expected_answer']}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nü§ñ GENERATED ANSWER:\\n{result['generated_answer']}\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "16815630fc674445b7df365ba985e757": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_f440cd55da25456c95d0a3112bcd682f",
      "style": "IPY_MODEL_649f0979ee2a40188bbb85a465dfc06a",
      "value": true
     }
    },
    "172c56acb79f497f8985590257be24ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "2191a707ba3a437eabc744405a64f93b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9552bbda5644379a4d3404cdd78203a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_71ef304dfd004056979996bd1079b5b7",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "322baa0ca70d4c998e1d894c8bf1b66f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_d46b43d325e34ae290de7270807640be",
      "style": "IPY_MODEL_7fe5b407fdf04726bee8399dd0db740c",
      "tooltip": ""
     }
    },
    "649f0979ee2a40188bbb85a465dfc06a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71ef304dfd004056979996bd1079b5b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e5bd2b3c937467ab011f471d19a7113": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fe5b407fdf04726bee8399dd0db740c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "8195b7fbb54f4fc9986ba5dd1232466a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_f3eff883b8044c91abed9e5cfabd1d39",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b3c002ec65d14394909d6202e8700300",
      "value": ""
     }
    },
    "93acf4c120144364a9e43a3937097baa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e5bd2b3c937467ab011f471d19a7113",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a77e316a928c48beb4ced6822ffafe7e",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "a77e316a928c48beb4ced6822ffafe7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9552bbda5644379a4d3404cdd78203a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3c002ec65d14394909d6202e8700300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d46b43d325e34ae290de7270807640be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3eff883b8044c91abed9e5cfabd1d39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f440cd55da25456c95d0a3112bcd682f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6083f262ff74f9c8dd3820ed787a4db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2191a707ba3a437eabc744405a64f93b",
       "IPY_MODEL_8195b7fbb54f4fc9986ba5dd1232466a",
       "IPY_MODEL_16815630fc674445b7df365ba985e757",
       "IPY_MODEL_322baa0ca70d4c998e1d894c8bf1b66f",
       "IPY_MODEL_93acf4c120144364a9e43a3937097baa"
      ],
      "layout": "IPY_MODEL_172c56acb79f497f8985590257be24ad"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
