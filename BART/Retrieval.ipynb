{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc608ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 171,284 characters\n",
      "Estimated pages: ~85\n"
     ]
    }
   ],
   "source": [
    "with open('Dataset/StudentHandbookDataset.txt', 'r', encoding='utf-8') as f:\n",
    "    dataset = f.read()\n",
    "\n",
    "print(f\"Dataset loaded: {len(dataset):,} characters\")\n",
    "print(f\"Estimated pages: ~{len(dataset) // 2000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fc4873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bed4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Chunking (RUN ONCE ONLY)\n",
    "\n",
    "This section handles text chunking and saves the results. You only need to run this **once** or when:\n",
    "- You update your dataset\n",
    "- You want to change chunking strategy (e.g., chunk size, overlap)\n",
    "- The saved chunks file is deleted\n",
    "\n",
    "**Note**: After running once, skip to Step 2 for embedding experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4552b943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] No saved chunks found. Run the chunking cells below.\n"
     ]
    }
   ],
   "source": [
    "def check_chunks_exist():\n",
    "    \"\"\"Check if chunks have been saved\"\"\"\n",
    "    return os.path.exists(\"saved_chunks/chunks.pkl\")\n",
    "\n",
    "def save_chunks(chunks, filename=\"saved_chunks/chunks.pkl\"):\n",
    "    \"\"\"Save chunks to disk\"\"\"\n",
    "    os.makedirs(\"saved_chunks\", exist_ok=True)\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(chunks, f)\n",
    "    print(f\"[SUCCESS] Saved {len(chunks)} chunks to {filename}\")\n",
    "\n",
    "def load_chunks(filename=\"saved_chunks/chunks.pkl\"):\n",
    "    \"\"\"Load chunks from disk\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            chunks = pickle.load(f)\n",
    "        print(f\"[SUCCESS] Loaded {len(chunks)} chunks from {filename}\")\n",
    "        return chunks\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[ERROR] Chunks file not found: {filename}\")\n",
    "        return None\n",
    "\n",
    "# Check if chunks already exist\n",
    "if check_chunks_exist():\n",
    "    print(\"[SUCCESS] Chunks file found! You can skip to Step 2 (Embedding Experiments)\")\n",
    "    print(\"[INFO] To reload chunks, run: chunks = load_chunks()\")\n",
    "else:\n",
    "    print(\"[INFO] No saved chunks found. Run the chunking cells below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9df2e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model for semantic chunking...\n",
      "   Using CPU for stable performance\n",
      "Setting up semantic chunker...\n",
      "[SUCCESS] Chunker ready (using CPU)!\n",
      "Setting up semantic chunker...\n",
      "[SUCCESS] Chunker ready (using CPU)!\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN THIS IF CHUNKS DON'T EXIST OR YOU WANT TO RE-CHUNK\n",
    "print(\"Loading embedding model for semantic chunking...\")\n",
    "print(\"   Using CPU for stable performance\")\n",
    "\n",
    "chunking_embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"Setting up semantic chunker...\")\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=chunking_embed_model,\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=80,\n",
    "    buffer_size=1,\n",
    "    add_start_index=True\n",
    ")\n",
    "print(\"[SUCCESS] Chunker ready (using CPU)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03aa1d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating semantic chunks from raw text...\n",
      "[SUCCESS] Created 246 semantic chunks\n",
      "\n",
      "Chunk Analysis:\n",
      "   Average size: 650 characters\n",
      "   Size range: 2 - 7102 characters\n",
      "   Total chunks: 246\n",
      "\n",
      "Sample chunks:\n",
      "   Chunk 1: ﻿Republic of the Philippines  Eulogio \"Amang\" Rodriguez Institute of Science and Technology Office of Student Affairs and Services   EARIST STUDENT HA...\n",
      "   Chunk 2: ii - HISTORY OF EARIST ..... 1 - MISSION STATEMENTS   - Vision ..... 3   - Mission ..... 3   - Goal ........\n",
      "   Chunk 3: 3   - Objectives ..... 3 - CURRICULAR OFFERINGS   - Main Campus     - College of Architecture and Fine Arts ..... 4     - College of Arts and Sciences...\n",
      "[SUCCESS] Saved 246 chunks to saved_chunks/chunks.pkl\n",
      "\n",
      "[SUCCESS] Chunking complete and saved! You won't need to run this again.\n",
      "[SUCCESS] Created 246 semantic chunks\n",
      "\n",
      "Chunk Analysis:\n",
      "   Average size: 650 characters\n",
      "   Size range: 2 - 7102 characters\n",
      "   Total chunks: 246\n",
      "\n",
      "Sample chunks:\n",
      "   Chunk 1: ﻿Republic of the Philippines  Eulogio \"Amang\" Rodriguez Institute of Science and Technology Office of Student Affairs and Services   EARIST STUDENT HA...\n",
      "   Chunk 2: ii - HISTORY OF EARIST ..... 1 - MISSION STATEMENTS   - Vision ..... 3   - Mission ..... 3   - Goal ........\n",
      "   Chunk 3: 3   - Objectives ..... 3 - CURRICULAR OFFERINGS   - Main Campus     - College of Architecture and Fine Arts ..... 4     - College of Arts and Sciences...\n",
      "[SUCCESS] Saved 246 chunks to saved_chunks/chunks.pkl\n",
      "\n",
      "[SUCCESS] Chunking complete and saved! You won't need to run this again.\n"
     ]
    }
   ],
   "source": [
    "# ONLY RUN THIS IF CHUNKS DON'T EXIST OR YOU WANT TO RE-CHUNK\n",
    "print(\"Creating semantic chunks from raw text...\")\n",
    "chunks = text_splitter.create_documents([dataset])\n",
    "print(f\"[SUCCESS] Created {len(chunks)} semantic chunks\")\n",
    "\n",
    "# Analyze chunk quality\n",
    "chunk_sizes = [len(chunk.page_content) for chunk in chunks]\n",
    "print(f\"\\nChunk Analysis:\")\n",
    "print(f\"   Average size: {np.mean(chunk_sizes):.0f} characters\")\n",
    "print(f\"   Size range: {min(chunk_sizes)} - {max(chunk_sizes)} characters\")\n",
    "print(f\"   Total chunks: {len(chunks)}\")\n",
    "\n",
    "# Show sample chunks\n",
    "print(\"\\nSample chunks:\")\n",
    "for i in range(min(3, len(chunks))):\n",
    "    chunk_preview = chunks[i].page_content[:150].replace('\\n', ' ')\n",
    "    print(f\"   Chunk {i+1}: {chunk_preview}...\")\n",
    "\n",
    "# SAVE THE CHUNKS!\n",
    "save_chunks(chunks)\n",
    "print(\"\\n[SUCCESS] Chunking complete and saved! You won't need to run this again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede42c88",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Load Chunks & Experiment with Embeddings\n",
    "\n",
    "Start here after chunking is done! This section lets you experiment with different embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc4640e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Loaded 246 chunks from saved_chunks/chunks.pkl\n",
      "[SUCCESS] Ready to experiment with 246 chunks!\n"
     ]
    }
   ],
   "source": [
    "# Load saved chunks\n",
    "chunks = load_chunks()\n",
    "\n",
    "if chunks is None:\n",
    "    print(\"[ERROR] Please run Step 1 (Chunking) first!\")\n",
    "else:\n",
    "    print(f\"[SUCCESS] Ready to experiment with {len(chunks)} chunks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc42cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose Your Embedding Model\n",
    "\n",
    "Experiment with different embedding models here! Uncomment the one you want to try:\n",
    "\n",
    "**Options:**\n",
    "- `all-mpnet-base-v2`: Best quality, slower (768 dim)\n",
    "- `all-MiniLM-L6-v2`: Fast, good quality (384 dim) \n",
    "- `multi-qa-mpnet-base-dot-v1`: Optimized for Q&A\n",
    "- `paraphrase-multilingual-mpnet-base-v2`: Multi-language support\n",
    "- Or try any model from https://huggingface.co/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f09544e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "   Using CPU for stable performance\n",
      "[SUCCESS] Embedding model loaded: all-mpnet-base-v2\n",
      "Embedding dimension: 768\n",
      "Device: CPU\n",
      "[SUCCESS] Embedding model loaded: all-mpnet-base-v2\n",
      "Embedding dimension: 768\n",
      "Device: CPU\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT: Choose your embedding model\n",
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"  # Change this to experiment!\n",
    "\n",
    "# Alternative options to try:\n",
    "# MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"  # Faster, smaller\n",
    "# MODEL_NAME = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"  # Q&A optimized\n",
    "# MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"  # Multilingual\n",
    "\n",
    "print(f\"\\nInitializing embedding model: {MODEL_NAME}\")\n",
    "print(\"   Using CPU for stable performance\")\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_kwargs={\n",
    "        'device': 'cpu',\n",
    "        'trust_remote_code': True\n",
    "    },\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# Get embedding dimension\n",
    "test_embed = embedding_model.embed_query(\"test\")\n",
    "\n",
    "print(f\"[SUCCESS] Embedding model loaded: {MODEL_NAME.split('/')[-1]}\")\n",
    "print(f\"Embedding dimension: {len(test_embed)}\")\n",
    "print(f\"Device: CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01f5e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for all chunks with current model...\n",
      "   Processed batch 1/8\n",
      "   Processed batch 1/8\n",
      "   Processed batch 2/8\n",
      "   Processed batch 2/8\n",
      "   Processed batch 3/8\n",
      "   Processed batch 3/8\n",
      "   Processed batch 4/8\n",
      "   Processed batch 4/8\n",
      "   Processed batch 5/8\n",
      "   Processed batch 5/8\n",
      "   Processed batch 6/8\n",
      "   Processed batch 6/8\n",
      "   Processed batch 7/8\n",
      "   Processed batch 7/8\n",
      "   Processed batch 8/8\n",
      "\n",
      "[SUCCESS] Generated 246 embeddings in 35.86s\n",
      "Average: 0.146s per chunk\n",
      "   Processed batch 8/8\n",
      "\n",
      "[SUCCESS] Generated 246 embeddings in 35.86s\n",
      "Average: 0.146s per chunk\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating embeddings for all chunks with current model...\")\n",
    "chunk_texts = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "# Process embeddings in batches to avoid memory issues\n",
    "batch_size = 32\n",
    "all_embeddings = []\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(0, len(chunk_texts), batch_size):\n",
    "    batch = chunk_texts[i:i+batch_size]\n",
    "    batch_embeddings = embedding_model.embed_documents(batch)\n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "    print(f\"   Processed batch {i//batch_size + 1}/{(len(chunk_texts) + batch_size - 1)//batch_size}\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\n[SUCCESS] Generated {len(all_embeddings)} embeddings in {elapsed_time:.2f}s\")\n",
    "print(f\"Average: {elapsed_time/len(all_embeddings):.3f}s per chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d5daa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building FAISS vector database...\n",
      "[SUCCESS] FAISS index ready: 246 vectors (768 dimensions)\n",
      "Model: all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "# Build FAISS vector store for fast similarity search\n",
    "print(\"\\nBuilding FAISS vector database...\")\n",
    "dimension = len(all_embeddings[0])\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product for cosine similarity\n",
    "\n",
    "# Normalize embeddings for proper cosine similarity\n",
    "embeddings_array = np.array(all_embeddings).astype('float32')\n",
    "faiss.normalize_L2(embeddings_array)\n",
    "index.add(embeddings_array)\n",
    "\n",
    "print(f\"[SUCCESS] FAISS index ready: {index.ntotal:,} vectors ({dimension} dimensions)\")\n",
    "print(f\"Model: {MODEL_NAME.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b1df0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Retrieval Testing\n",
    "\n",
    "Now test your retrieval system with the current embedding model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cacb9040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Retrieval functions ready!\n"
     ]
    }
   ],
   "source": [
    "def retrieve_relevant_chunks(query, top_k=5):\n",
    "    \"\"\"Find most relevant chunks for the query\"\"\"\n",
    "    print(f\"\\nSearching for: '{query}'\")\n",
    "    print(f\"Model: {MODEL_NAME.split('/')[-1]}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Embed the query\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    query_vector = np.array([query_embedding]).astype('float32')\n",
    "    faiss.normalize_L2(query_vector)\n",
    "\n",
    "    # Search FAISS index\n",
    "    scores, indices = index.search(query_vector, top_k)\n",
    "\n",
    "    # Return results with metadata\n",
    "    results = []\n",
    "    for idx, score in zip(indices[0], scores[0]):\n",
    "        if idx < len(chunks):  # Safety check\n",
    "            chunk = chunks[idx]\n",
    "            results.append({\n",
    "                'text': chunk.page_content,\n",
    "                'score': float(score),\n",
    "                'chunk_id': int(idx),\n",
    "                'start_pos': chunk.metadata.get('start_index', 0) if hasattr(chunk, 'metadata') else 0\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "def display_retrieval_results(query, results):\n",
    "    \"\"\"Display comprehensive retrieval results\"\"\"\n",
    "    print(f\"Found {len(results)} relevant chunks for: '{query}'\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\nChunk {i} (ID: {result['chunk_id']})\")\n",
    "        print(f\"Relevance Score: {result['score']:.4f}\")\n",
    "        print(f\"Position in Document: Character {result['start_pos']:,}\")\n",
    "        print(f\"Length: {len(result['text'])} characters\")\n",
    "        print(f\"Content Preview (first 200 chars):\")\n",
    "        print(f\"   {result['text'][:200].replace(chr(10), ' ').replace(chr(13), '')}...\")\n",
    "        \n",
    "        # Show full content if it's short enough\n",
    "        if len(result['text']) <= 500:\n",
    "            print(f\"Full Content:\")\n",
    "            print(f\"   {result['text']}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"[SUCCESS] Retrieval functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cc5755",
   "metadata": {},
   "source": [
    "## Understanding `top_k=5`\n",
    "\n",
    "The `top_k=5` parameter means we retrieve the **5 most relevant chunks** for each query. Here's what this does:\n",
    "\n",
    "1. **Similarity Search**: When you ask a question, the system converts it to a vector and finds the most similar document chunks\n",
    "2. **Ranking**: All chunks get a similarity score (0-1, where 1 is perfect match)\n",
    "3. **Top Results**: We take only the top 5 highest-scoring chunks\n",
    "4. **Why 5?**: This balances between:\n",
    "   - **Coverage**: Enough context to answer most questions\n",
    "   - **Quality**: Avoiding too many irrelevant results\n",
    "   - **Speed**: Faster processing with fewer chunks\n",
    "\n",
    "**You can adjust this number**:\n",
    "- `top_k=3`: Fewer, more focused results\n",
    "- `top_k=10`: More comprehensive but potentially noisier results\n",
    "- `top_k=1`: Just the single best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f9e1517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Retrieval System!\n",
      "==================================================\n",
      "Running test queries...\n",
      "\n",
      "Searching for: 'What are the graduation requirements?'\n",
      "Model: all-mpnet-base-v2\n",
      "==================================================\n",
      "Found 5 relevant chunks for: 'What are the graduation requirements?'\n",
      "======================================================================\n",
      "\n",
      "Chunk 1 (ID: 84)\n",
      "Relevance Score: 0.6105\n",
      "Position in Document: Character 59,469\n",
      "Length: 86 characters\n",
      "Content Preview (first 200 chars):\n",
      "   2. Must carry a minimum academic load of 18 units (except for graduating students). 3....\n",
      "Full Content:\n",
      "   2. Must carry a minimum academic load of 18 units (except for graduating students). 3.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 2 (ID: 85)\n",
      "Relevance Score: 0.5864\n",
      "Position in Document: Character 59,555\n",
      "Length: 161 characters\n",
      "Content Preview (first 200 chars):\n",
      "   Must have a passing grade in all subjects including P.E. and NSTP (MTSLTS/CWTS) enrolled in order to qualify for continuance for the following semester. ##### b....\n",
      "Full Content:\n",
      "   Must have a passing grade in all subjects including P.E. and NSTP (MTSLTS/CWTS) enrolled in order to qualify for continuance for the following semester. ##### b.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 3 (ID: 51)\n",
      "Relevance Score: 0.5534\n",
      "Position in Document: Character 50,050\n",
      "Length: 2836 characters\n",
      "Content Preview (first 200 chars):\n",
      "   ### 10.2.2 Every candidate for graduation with honors must:   #### 10.2.4.1 Have carried the normal load prescribed in his/her curriculum (Art. II Sec.1); have completed the program within the prescri...\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 4 (ID: 65)\n",
      "Relevance Score: 0.5497\n",
      "Position in Document: Character 56,945\n",
      "Length: 73 characters\n",
      "Content Preview (first 200 chars):\n",
      "   TERTIARY EDUCATION PROGRAM   ##### a. Qualifications 1. Must be enrolled....\n",
      "Full Content:\n",
      "   TERTIARY EDUCATION PROGRAM\n",
      "\n",
      "\n",
      "##### a. Qualifications\n",
      "1. Must be enrolled.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 5 (ID: 50)\n",
      "Relevance Score: 0.5386\n",
      "Position in Document: Character 49,366\n",
      "Length: 684 characters\n",
      "Content Preview (first 200 chars):\n",
      "   ## SECTION 10. GRADUATION WITH HONORS   ### 10.1 The College Dean/Campus Administrator, in close coordination with the College Registrar, shall recommend a student who completes his baccalaureate cour...\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': '2. Must carry a minimum academic load of 18 units (except for graduating students). 3.',\n",
       "  'score': 0.6104676723480225,\n",
       "  'chunk_id': 84,\n",
       "  'start_pos': 59469},\n",
       " {'text': 'Must have a passing grade in all subjects including P.E. and NSTP (MTSLTS/CWTS) enrolled in order to qualify for continuance for the following semester. ##### b.',\n",
       "  'score': 0.5863968133926392,\n",
       "  'chunk_id': 85,\n",
       "  'start_pos': 59555},\n",
       " {'text': '### 10.2.2 Every candidate for graduation with honors must:\\n\\n\\n#### 10.2.4.1 Have carried the normal load prescribed in his/her curriculum (Art. II Sec.1); have completed the program within the prescribed number of years, four (4) years for the four-year program and five (5) years for the five-year program. #### 10.2.4.2 Have completed at least 75% of the total number of the academic units or hours required for graduation in the Institute. #### 10.2.4.3 Have been in residence for at least three years immediately prior to graduation. #### 10.2.4.4 Have no final grade lower than 2.25 in the curriculum in any academic and non-academic the student has taken in the Institute or in any other recognized educational Institution. #### 10.2.4.5 Have no incomplete, dropped and final grades of 5.0 in any academic and non-academic courses in the Institute or in any other recognized educational Institution. #### 10.2.4.6 Have not repeated a course (or subject) from another recognized educational institute. ## SECTION 11. SCHOLASTIC DELINQUENCY\\n\\n\\n### 11.1 Warning\\n\\n\\n#### 11.1.1 Any student who at the end of the semester obtains final grades of “5.00” in three (3) courses, accumulated or otherwise, shall be warned by the Dean/Campus Administrator concerned to improve his/her performance. #### 11.1.2 Any student who gets incomplete marks in 16 to 30 percent of the total number of academic units in which he/she is registered, he/she shall be warned by the Dean and his/her load shall be reduced by 3 units. ### 11.2 Probation\\n\\n\\n#### 11.2.1 Students who previously have a failing grade and still accumulate one in the succeeding semester in at least one (1) of his/her subject will be placed on probation. #### 11.2.2 Any student who accumulates 5 failing grades shall be automatically placed on probation for the succeeding semester and his/her academic load shall be reduced by the Dean concerned as stipulated in Art. II Sec. 7.2. #### 11.2.3 Probation shall be lifted once a student has passed all his/her subjects in the following semester. #### 11.2.4 Students who have been placed on probation for two successive semesters shall be dropped from the rolls of the College in which he/she is enrolled. However, he/she may be readmitted to another College of the Institute to which he/she qualifies. #### 11.2.5 Student on probation who again fails in 50 percent or more of the total number of units in which he/she receives final grades shall be dropped from the rolls of the Institute. ## SECTION 12. ON-THE-JOB TRAINING/ PRACTICUM / INTERNSHIP / PRACTICE TEACHING\\n\\n\\n### 12.1 Each student who will undergo training/ On-the-Job Training/ Practicum/ Internship/ Practice Teaching shall:\\n\\n\\n#### 12.1.1 Enroll in practicum or equivalent course. #### 12.1.2 Be in good academic standing and completed all pre-requisite subjects [Art.',\n",
       "  'score': 0.5534185767173767,\n",
       "  'chunk_id': 51,\n",
       "  'start_pos': 50050},\n",
       " {'text': 'TERTIARY EDUCATION PROGRAM\\n\\n\\n##### a. Qualifications\\n1. Must be enrolled.',\n",
       "  'score': 0.5496562123298645,\n",
       "  'chunk_id': 65,\n",
       "  'start_pos': 56945},\n",
       " {'text': '## SECTION 10. GRADUATION WITH HONORS\\n\\n\\n### 10.1 The College Dean/Campus Administrator, in close coordination with the College Registrar, shall recommend a student who completes his baccalaureate course with any of the following cumulative grade point averages to be graduated with honors:\\n\\n\\nHonor: Summa cum Laude\\n* Required Grade Range: 1.2500 to 1.0000\\nHonor: Magna cum Laude\\n* Required Grade Range: 1.5000 to 1.2501\\nHonor: Cum Laude\\n* Required Grade Range: 1.7500 to 1.5001\\n### 10.2.1 In the computation of the final average of a Candidate for Graduation with honors, grades in all accredited academic courses in the curriculum (including P.E. and NSTP courses) shall be included.',\n",
       "  'score': 0.5385792255401611,\n",
       "  'chunk_id': 50,\n",
       "  'start_pos': 49366}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the retrieval system with sample queries\n",
    "print(\"\\nTesting Retrieval System!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sample test questions for university handbook\n",
    "test_questions = [\n",
    "    \"What are the graduation requirements?\",\n",
    "    \"How do I withdraw from a course?\",\n",
    "    \"What is the academic probation policy?\",\n",
    "    \"What happens if I'm caught cheating?\",\n",
    "    \"How do I change my major?\"\n",
    "]\n",
    "\n",
    "print(\"Running test queries...\")\n",
    "\n",
    "# Test with the first question\n",
    "test_query = test_questions[0]\n",
    "test_results = retrieve_relevant_chunks(test_query, top_k=5)\n",
    "display_retrieval_results(test_query, test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de11cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Interactive retrieval function ready!\n",
      "[INFO] Call interactive_retrieval() to start testing!\n"
     ]
    }
   ],
   "source": [
    "def interactive_retrieval():\n",
    "    \"\"\"Interactive mode for testing retrieval\"\"\"\n",
    "    print(f\"\\nInteractive Retrieval Testing Mode\")\n",
    "    print(f\"Current model: {MODEL_NAME.split('/')[-1]}\")\n",
    "    print(\"Test how well the system finds relevant information!\")\n",
    "    print(\"Type 'quit' to exit, 'batch' to run all test questions, or 'help' for commands\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    while True:\n",
    "        question = input(\"\\n❓ Enter your question (or command): \").strip()\n",
    "\n",
    "        if question.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"Goodbye! To try a different embedding model, change MODEL_NAME and re-run from Step 2.\")\n",
    "            break\n",
    "            \n",
    "        elif question.lower() == 'help':\n",
    "            print(\"Available commands:\")\n",
    "            print(\"   'quit' or 'q' - Exit interactive mode\")\n",
    "            print(\"   'batch' - Run all predefined test questions\")\n",
    "            print(\"   'test1', 'test2', etc. - Run specific test question\")\n",
    "            print(\"   'model' - Show current embedding model\")\n",
    "            print(\"   Or just type any question to search!\")\n",
    "            continue\n",
    "            \n",
    "        elif question.lower() == 'model':\n",
    "            print(f\"Current embedding model: {MODEL_NAME}\")\n",
    "            print(f\"Embedding dimension: {len(all_embeddings[0])}\")\n",
    "            print(f\"Total chunks indexed: {len(chunks)}\")\n",
    "            continue\n",
    "            \n",
    "        elif question.lower() == 'batch':\n",
    "            print(\"\\nRunning batch test of all questions...\")\n",
    "            for i, test_q in enumerate(test_questions, 1):\n",
    "                print(f\"\\n{'='*20} TEST {i}/5 {'='*20}\")\n",
    "                results = retrieve_relevant_chunks(test_q, top_k=3)  # Use top_k=3 for batch\n",
    "                display_retrieval_results(test_q, results)\n",
    "            continue\n",
    "            \n",
    "        elif question.lower().startswith('test') and len(question) > 4 and question[4:].isdigit():\n",
    "            test_num = int(question[4:]) - 1\n",
    "            if 0 <= test_num < len(test_questions):\n",
    "                test_q = test_questions[test_num]\n",
    "                print(f\"\\nRunning test question {test_num + 1}\")\n",
    "                results = retrieve_relevant_chunks(test_q, top_k=5)\n",
    "                display_retrieval_results(test_q, results)\n",
    "            else:\n",
    "                print(f\"[ERROR] Test number must be between 1 and {len(test_questions)}\")\n",
    "            continue\n",
    "\n",
    "        if not question:\n",
    "            print(\"Please enter a question!\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            results = retrieve_relevant_chunks(question, top_k=5)\n",
    "            display_retrieval_results(question, results)\n",
    "            \n",
    "            # Ask if user wants to try different top_k values\n",
    "            while True:\n",
    "                modify = input(\"\\nTry different number of results? (Enter number 1-10, or 'n' for no): \").strip()\n",
    "                if modify.lower() in ['n', 'no', '']:\n",
    "                    break\n",
    "                elif modify.isdigit() and 1 <= int(modify) <= 10:\n",
    "                    new_k = int(modify)\n",
    "                    print(f\"\\nRetrieving top {new_k} results...\")\n",
    "                    new_results = retrieve_relevant_chunks(question, top_k=new_k)\n",
    "                    display_retrieval_results(question, new_results)\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Please enter a number between 1-10 or 'n'\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {str(e)}\")\n",
    "\n",
    "print(\"[SUCCESS] Interactive retrieval function ready!\")\n",
    "print(\"[INFO] Call interactive_retrieval() to start testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73b3c04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interactive Retrieval Testing Mode\n",
      "Current model: all-mpnet-base-v2\n",
      "Test how well the system finds relevant information!\n",
      "Type 'quit' to exit, 'batch' to run all test questions, or 'help' for commands\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Searching for: 'what is the requirement if i want to apply for computer science'\n",
      "Model: all-mpnet-base-v2\n",
      "==================================================\n",
      "Found 5 relevant chunks for: 'what is the requirement if i want to apply for computer science'\n",
      "======================================================================\n",
      "\n",
      "Chunk 1 (ID: 83)\n",
      "Relevance Score: 0.5325\n",
      "Position in Document: Character 59,388\n",
      "Length: 81 characters\n",
      "Content Preview (first 200 chars):\n",
      "   Qualifications 1. Currently enrolled in one of the courses in any of the college....\n",
      "Full Content:\n",
      "   Qualifications\n",
      "1. Currently enrolled in one of the courses in any of the college.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 2 (ID: 30)\n",
      "Relevance Score: 0.5012\n",
      "Position in Document: Character 14,536\n",
      "Length: 2316 characters\n",
      "Content Preview (first 200 chars):\n",
      "   Admission Requirements   #### 1. Freshmen 1.1 Form 138 (Senior and High School Report Card)   1.2 Certificate of Good Moral Character with school seal   1.3 Birth Certificate (PSA Authenticated)   1.4...\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 3 (ID: 36)\n",
      "Relevance Score: 0.4613\n",
      "Position in Document: Character 22,875\n",
      "Length: 47 characters\n",
      "Content Preview (first 200 chars):\n",
      "   Admission Recommendation from the College Dean....\n",
      "Full Content:\n",
      "   Admission Recommendation from the College Dean.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 4 (ID: 28)\n",
      "Relevance Score: 0.4522\n",
      "Position in Document: Character 13,858\n",
      "Length: 285 characters\n",
      "Content Preview (first 200 chars):\n",
      "   The number of applicants to be admitted depends on the resources of the Institute such as rooms and faculty. **Admission Qualifications of Local Student/s.** The following students are eligible to app...\n",
      "Full Content:\n",
      "   The number of applicants to be admitted depends on the resources of the Institute such as rooms and faculty. **Admission Qualifications of Local Student/s.** The following students are eligible to apply for admission in EARIST:\n",
      "\n",
      "\n",
      "#### Freshmen\n",
      "- All Grade 12 graduates [CMO No. 105, s.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 5 (ID: 31)\n",
      "Relevance Score: 0.4519\n",
      "Position in Document: Character 16,852\n",
      "Length: 4713 characters\n",
      "Content Preview (first 200 chars):\n",
      "   The evaluation of the interviewer is final and unappealable. ### Screening Level 3: Program Preparedness Test Program Preparedness Tests are placement examinations specifically designed to assess comp...\n",
      "----------------------------------------\n",
      "\n",
      "Searching for: 'what is the requirement if i want to apply for computer science'\n",
      "Model: all-mpnet-base-v2\n",
      "==================================================\n",
      "Found 5 relevant chunks for: 'what is the requirement if i want to apply for computer science'\n",
      "======================================================================\n",
      "\n",
      "Chunk 1 (ID: 83)\n",
      "Relevance Score: 0.5325\n",
      "Position in Document: Character 59,388\n",
      "Length: 81 characters\n",
      "Content Preview (first 200 chars):\n",
      "   Qualifications 1. Currently enrolled in one of the courses in any of the college....\n",
      "Full Content:\n",
      "   Qualifications\n",
      "1. Currently enrolled in one of the courses in any of the college.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 2 (ID: 30)\n",
      "Relevance Score: 0.5012\n",
      "Position in Document: Character 14,536\n",
      "Length: 2316 characters\n",
      "Content Preview (first 200 chars):\n",
      "   Admission Requirements   #### 1. Freshmen 1.1 Form 138 (Senior and High School Report Card)   1.2 Certificate of Good Moral Character with school seal   1.3 Birth Certificate (PSA Authenticated)   1.4...\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 3 (ID: 36)\n",
      "Relevance Score: 0.4613\n",
      "Position in Document: Character 22,875\n",
      "Length: 47 characters\n",
      "Content Preview (first 200 chars):\n",
      "   Admission Recommendation from the College Dean....\n",
      "Full Content:\n",
      "   Admission Recommendation from the College Dean.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 4 (ID: 28)\n",
      "Relevance Score: 0.4522\n",
      "Position in Document: Character 13,858\n",
      "Length: 285 characters\n",
      "Content Preview (first 200 chars):\n",
      "   The number of applicants to be admitted depends on the resources of the Institute such as rooms and faculty. **Admission Qualifications of Local Student/s.** The following students are eligible to app...\n",
      "Full Content:\n",
      "   The number of applicants to be admitted depends on the resources of the Institute such as rooms and faculty. **Admission Qualifications of Local Student/s.** The following students are eligible to apply for admission in EARIST:\n",
      "\n",
      "\n",
      "#### Freshmen\n",
      "- All Grade 12 graduates [CMO No. 105, s.\n",
      "----------------------------------------\n",
      "\n",
      "Chunk 5 (ID: 31)\n",
      "Relevance Score: 0.4519\n",
      "Position in Document: Character 16,852\n",
      "Length: 4713 characters\n",
      "Content Preview (first 200 chars):\n",
      "   The evaluation of the interviewer is final and unappealable. ### Screening Level 3: Program Preparedness Test Program Preparedness Tests are placement examinations specifically designed to assess comp...\n",
      "----------------------------------------\n",
      "Please enter a question!\n",
      "Please enter a question!\n",
      "Goodbye! To try a different embedding model, change MODEL_NAME and re-run from Step 2.\n",
      "Goodbye! To try a different embedding model, change MODEL_NAME and re-run from Step 2.\n"
     ]
    }
   ],
   "source": [
    "# Start interactive mode\n",
    "interactive_retrieval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
